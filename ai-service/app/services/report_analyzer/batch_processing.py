"""
Servi√ßos de processamento em lote para relat√≥rios XP.
"""
import asyncio
from app.workflows.report_workflow import create_report_analysis_workflow
from app.config import MAX_CONCURRENT_JOBS

# Sem√°foro global para limitar concorr√™ncia de jobs em toda a inst√¢ncia
semaphore = asyncio.Semaphore(MAX_CONCURRENT_JOBS)

async def process_batch_reports(files_data: list, user_id: str) -> list:
    """
    Processa m√∫ltiplos relat√≥rios em paralelo, respeitando o limite global de concorr√™ncia.
    """
    async def process_single_file(file_data: dict) -> dict:
        try:
            print(f"[batch] Iniciando processamento de: {file_data['name']}")
            
            # Adquirir sem√°foro antes de processar
            async with semaphore:
                print(f"[batch] üü¢ Sem√°foro adquirido para: {file_data['name']} (Livres: {MAX_CONCURRENT_JOBS - semaphore._value})")
                
                state = {
                    "file_content": file_data["dataUri"],
                    "file_name": file_data["name"],
                    "user_id": user_id,
                    "analysis_mode": "auto",
                    "selected_fields": None
                }
                
                print(f"[batch] Chamando report_analysis_app.ainvoke para: {file_data['name']}")
                
                # Adicionar timeout de 4 minutos por arquivo
                try:
                    app = create_report_analysis_workflow()
                    result = await asyncio.wait_for(
                        app.ainvoke(state),
                        timeout=240.0  # 4 minutos
                    )
                    print(f"[batch] ‚úÖ Conclu√≠do: {file_data['name']}")
                except asyncio.TimeoutError:
                    print(f"[batch] ‚è∞ Timeout em: {file_data['name']}")
                    raise Exception(f"Timeout no processamento de {file_data['name']}")
            
            # Sem√°foro liberado automaticamente aqui
            return {
                "success": True,
                "file_name": file_data["name"],
                "data": result
            }
            
        except Exception as e:
            print(f"[batch] ‚ùå Erro em {file_data['name']}: {e}")
            return {
                "success": False,
                "file_name": file_data["name"],
                "error": str(e)
            }
    
    print(f"[batch] Iniciando processamento de {len(files_data)} arquivos")
    
    # Processar em paralelo
    tasks = [process_single_file(file_data) for file_data in files_data]
    print(f"[batch] Criadas {len(tasks)} tasks")
    
    try:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        print(f"[batch] Processamento conclu√≠do, {len(results)} resultados")
    except Exception as e:
        print(f"[batch] Erro no asyncio.gather: {e}")
        return []
    
    # Tratar exce√ß√µes
    processed_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"[batch] Exce√ß√£o no arquivo {i}: {result}")
            processed_results.append({
                "success": False,
                "file_name": files_data[i]["name"],
                "error": str(result)
            })
        else:
            processed_results.append(result)
    
    print(f"[batch] Retornando {len(processed_results)} resultados processados")
    return processed_results